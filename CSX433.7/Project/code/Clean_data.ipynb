{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data\n",
    "\n",
    "Clean data based on EDA analysis. Those features are going to be removed.\n",
    "  \n",
    "- recorded_by is the same for all the samples, need to be removed\n",
    "- num_private has most missing values (98.7%), need to be removed\n",
    "- amount_tsh has 2nd most missing values (70%), need to be removed\n",
    "- scheme_name has 47.418% samples with missing value, need to be removed\n",
    "- wpt_name and subvillage due to so many unique values\n",
    "\n",
    "- “lga”,“region”,“basin” ,correlated other region information\n",
    "- “extraction_type_group”,“extraction_type_class”, correlated with ‘extraction_type’\n",
    "- “management_group”, correlated with ‘management’\n",
    "- “payment_type”, correlated with ‘payment’\n",
    "- “quality_group”, correlated with ‘quality’\n",
    "- “quantity_group”, correlated with ‘quantity’\n",
    "- “source_type”,“source_class”, correlated with ‘source’\n",
    "- “waterpoint_type_group”, correlated with ‘waterpoint_type’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_dat(d):\n",
    "    ids = d['id']\n",
    "    d = d.drop(labels=['id'],axis=1)\n",
    "  \n",
    "    ## Removing those features ###\n",
    "    # recorded_by is the same for all the samples, need to be removed\n",
    "    # num_private has most missing values (98.7%), need to be removed\n",
    "    # amount_tsh has 2nd most missing values (70%), need to be removed\n",
    "    # scheme_name has 47.418% samples with missing value, need to be removed\n",
    "    # wpt_name and subvillage due to so many unique values\n",
    "    # \n",
    "    # “lga”,“region”,“basin” ,correlated other region information\n",
    "    # “extraction_type_group”,“extraction_type_class”, correlated with ‘extraction_type’\n",
    "    # “management_group”, correlated with ‘management’\n",
    "    # “payment_type”, correlated with ‘payment’\n",
    "    # “quality_group”, correlated with ‘quality’\n",
    "    # “quantity_group”, correlated with ‘quantity’\n",
    "    # “source_type”,“source_class”, correlated with ‘source’\n",
    "    # “waterpoint_type_group”, correlated with ‘waterpoint_type’\n",
    "    removed_labels = ['recorded_by','num_private','scheme_name','wpt_name','subvillage',\n",
    "                      'lga','region','basin',\n",
    "                      'extraction_type_group','extraction_type_class',\n",
    "                      'management_group',\n",
    "                      'payment_type',\n",
    "                      'quality_group',\n",
    "                      'quantity_group',\n",
    "                      'source_type','source_class',\n",
    "                      'waterpoint_type_group']\n",
    "    d = d.drop(labels=removed_labels,axis=1)\n",
    "    \n",
    "    ### Convert 0 into NA\n",
    "    d.loc[d.funder==\"0\",'funder'] = np.NAN  \n",
    "    d.loc[d.installer==\"0\",'installer']= np.NAN\n",
    "    d.loc[d.installer==\"-\",'installer']= np.NAN\n",
    "    d.loc[d.longitude==0,'longitude'] = np.NAN\n",
    "    d.loc[d.district_code==0,'district_code'] = np.NAN\n",
    "    d.loc[d.construction_year==0,'construction_year'] = np.NAN\n",
    "    \n",
    "    ### date_recorded into year, month, week and days to 2014-01-01\n",
    "    d['date_recorded_year'] =  [date.split(\"-\")[0] for date in d.date_recorded]\n",
    "    d['date_recorded_month'] = [date.split(\"-\")[1] for date in d.date_recorded]\n",
    "    d['date_recorded_week'] = [datetime.datetime.strptime(date,\"%Y-%m-%d\").weekday()  for date in d.date_recorded]\n",
    "    d['date_recorded_offset_days'] = [(datetime.datetime(2014,1,1) - datetime.datetime.strptime(date,\"%Y-%m-%d\")).days for date in d.date_recorded]\n",
    "    \n",
    "    d = d.drop(labels=\"date_recorded\",axis=1)\n",
    "    \n",
    "    def reduce_category_levels(x,max_levels=30):\n",
    "        xx = x.value_counts(sort=True)\n",
    "        if(len(xx)>max_levels):\n",
    "            keeps = xx.index[:max_levels]\n",
    "            x = [s if s in keeps else \"Others\" for s in x]\n",
    "        return x    \n",
    "    ## For those 3 categories, reduce to 30 lelves\n",
    "    ## funder\t1896\n",
    "    ## ward\t2092\n",
    "    ## installer\t2143        \n",
    "    \n",
    "    d.loc[:,\"funder\"] = reduce_category_levels(d.funder)\n",
    "    d.loc[:,'ward'] = reduce_category_levels(d.ward)\n",
    "    d.loc[:,'installer']=reduce_category_levels(d.installer)\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = pd.read_csv(\"../data/train.csv\")\n",
    "d_test = pd.read_csv(\"../data/test.csv\")\n",
    "id_test = d_test.id\n",
    "n = d_train.shape[0]  ## total rows of training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d_train.append(d_test)\n",
    "d_cleaned = clean_dat(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_train_cleaned = d_cleaned.iloc[:n]\n",
    "d_test_cleaned = d_cleaned.iloc[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train_cleaned.to_csv(path_or_buf=\"../data/train_clean.csv\",index=False)\n",
    "d_test_cleaned.to_csv(path_or_buf=\"../data/test_clean.csv\",index=False)\n",
    "id_test.to_frame().to_csv(path_or_buf = \"../data/test_id.csv\",index=False )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
