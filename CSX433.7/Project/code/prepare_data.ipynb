{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for ML\n",
    "\n",
    "\n",
    "We will take the output from thee **Clean_data** analysis and convert the category feature into dummy varaibles\n",
    "output will be:\n",
    "- Split the training set into 80/20 trainning and validation\n",
    "- Take the whole testing(without labels) as testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_features(d):\n",
    "    category_columns = d.dtypes[d.dtypes == object]\n",
    "    return pd.get_dummies(d, columns=category_columns.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dTrain = pd.read_csv(\"../data/train_clean.csv\")\n",
    "dTest = pd.read_csv(\"../data/test_clean.csv\")\n",
    "n = dTrain.shape[0] ## total rows of training\n",
    "d = make_features(dTrain.append(dTest))\n",
    "d = d.astype(float)\n",
    "\n",
    "## Testing and training\n",
    "dTrain_transformed = d.iloc[:n]\n",
    "dTest_transformed = d.iloc[n:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Read Training labels\n",
    "LTrain = pd.read_csv(\"../data/train_label.csv\").iloc[:,1]\n",
    "LTrain = LTrain.astype(\"category\")\n",
    "LTrain_coded = np.array(LTrain.cat.codes.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idTest = pd.read_csv(\"../data/test_id.csv\")  ## dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Instead of using sklean.model_selection.train_test_split,\n",
    "## We use numpy to resampling\n",
    "np.random.seed(123)\n",
    "training_idx = np.random.randint(dTrain_transformed.shape[0],size=int(dTrain_transformed.shape[0]*0.8))\n",
    "validation_idx = np.random.randint(dTrain_transformed.shape[0],size=int(dTrain_transformed.shape[0]*0.2))\n",
    "\n",
    "data_train,data_validation = dTrain_transformed.as_matrix()[training_idx],dTrain_transformed.as_matrix()[validation_idx]\n",
    "labels_train,labels_validation = LTrain_coded[training_idx],LTrain_coded[validation_idx]\n",
    "labels_category_train,labels_category_validation = LTrain[training_idx],LTrain[validation_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Write out by pickles\n",
    "training = {\"features\": data_train,  \"label\":labels_train,\"label_original\":labels_category_train}\n",
    "validating = {\"features\": data_validation,  \"label\":labels_validation,\"label_original\":labels_category_validation}\n",
    "testing = {\"features\": dTest_transformed.as_matrix(),  \"id\":idTest}\n",
    "\n",
    "outd = {\"train\":training,\"validation\":validating, \"test\":testing,}\n",
    "\n",
    "with open('../data/features.pickle', 'wb') as handle:\n",
    "    pickle.dump(outd, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy\t1.13.3\n",
      "pandas\t0.20.3\n"
     ]
    }
   ],
   "source": [
    "#find the names of the imported modules\n",
    "import types\n",
    "def imports():\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            yield val.__name__\n",
    "\n",
    "#exclude all modules not listed by `!pip freeze`\n",
    "excludes = ['__builtin__', 'types', 'IPython.core.shadowns', 'sys', 'os']\n",
    "imported_modules = [module for module in imports() if module not in excludes]\n",
    "pip_modules = !pip freeze #you could also use `!conda list` with anaconda\n",
    "\n",
    "#print the names and versions of the imported modules\n",
    "for module in pip_modules:\n",
    "    name, version = module.split('==')\n",
    "    if name in imported_modules:\n",
    "        print(name + '\\t' + version)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
